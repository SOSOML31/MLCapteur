{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9597043-8156-4118-b342-1d0cc823a3b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Pour le machine learning\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Pour le machine learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# ================================================================\n",
    "#                 Définition des chemins de fichiers\n",
    "# ================================================================\n",
    "file_training = \"captor_1_sample_2_with_manual_validation.csv\"  # Contient action_valide (corrigé manuellement)\n",
    "file_with_null = \"captor_2_with_null.csv\"                       # Exemple pour l'imputation\n",
    "file_todo = \"captor_3_todo.csv\"                                 # Données à corriger + prédire\n",
    "\n",
    "# ================================================================\n",
    "#                      Chargement des données\n",
    "# ================================================================\n",
    "df_training = pd.read_csv(file_training)\n",
    "df_null = pd.read_csv(file_with_null)\n",
    "df_todo = pd.read_csv(file_todo)\n",
    "\n",
    "# ================================================================\n",
    "#         Vérification de la présence de valeurs manquantes\n",
    "# ================================================================\n",
    "def check_missing(df, df_name):\n",
    "    print(f\"Valeurs manquantes dans {df_name}:\")\n",
    "    print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "check_missing(df_training, \"df_training\")\n",
    "check_missing(df_null, \"df_null\")\n",
    "check_missing(df_todo, \"df_todo\")\n",
    "\n",
    "# ================================================================\n",
    "#        Imputation des valeurs manquantes via KNNImputer\n",
    "# ================================================================\n",
    "num_cols = [\"temp\", \"sis\", \"hygro\", \"anem1\", \"anem2\"]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# On corrige les valeurs manquantes dans df_training et df_null\n",
    "df_training[num_cols] = imputer.fit_transform(df_training[num_cols])\n",
    "df_null[num_cols] = imputer.transform(df_null[num_cols])\n",
    "df_todo[num_cols] = imputer.transform(df_todo[num_cols])\n",
    "\n",
    "# ================================================================\n",
    "#      Mapping des actions (A=0, B=1, C=2, SB=3) pour l'entraînement\n",
    "# ================================================================\n",
    "action_mapping = {\"A\": 0, \"B\": 1, \"C\": 2, \"SB\": 3}\n",
    "reverse_mapping = {v: k for k, v in action_mapping.items()}\n",
    "\n",
    "# On s'assure que la colonne 'action_valide' existe pour l'entraînement\n",
    "if \"action_valide\" not in df_training.columns:\n",
    "    raise ValueError(\"La colonne 'action_valide' n'existe pas dans df_training. Impossible de s'entraîner.\")\n",
    "\n",
    "df_training[\"action_valide\"] = df_training[\"action_valide\"].map(action_mapping)\n",
    "\n",
    "# ================================================================\n",
    "#                 Construction du dataset d'entraînement\n",
    "# ================================================================\n",
    "X = df_training[num_cols]\n",
    "y = df_training[\"action_valide\"]\n",
    "\n",
    "# Séparation en jeu d'entraînement / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "#           Entraînement du modèle (XGBoost de préférence)\n",
    "# ================================================================\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ================================================================\n",
    "#         Évaluation du modèle sur le jeu de test interne\n",
    "# ================================================================\n",
    "preds_test = model.predict(X_test)\n",
    "score = accuracy_score(y_test, preds_test)\n",
    "print(\"Précision du modèle (Accuracy) sur le test set:\", score)\n",
    "\n",
    "# ================================================================\n",
    "#        Application du modèle sur le fichier TODO\n",
    "# ================================================================\n",
    "df_todo[\"action\"] = model.predict(df_todo[num_cols])\n",
    "df_todo[\"action\"] = df_todo[\"action\"].map(reverse_mapping)\n",
    "\n",
    "# ================================================================\n",
    "#      Sauvegarde du fichier corrigé avec la colonne 'action'\n",
    "# ================================================================\n",
    "output_file = \"captor_3_todo_corrected.csv\"\n",
    "df_todo.to_csv(output_file, index=False)\n",
    "print(f\"Fichier '{output_file}' généré avec succès !\")\n",
    "\n",
    "# ================================================================\n",
    "#             Soumission du fichier corrigé à l'API\n",
    "# ================================================================\n",
    "url = \"http://20.216.208.68\"  # URL de l'API fournie\n",
    "try:\n",
    "    with open(output_file, \"rb\") as f:\n",
    "        response = requests.post(url, files={\"file\": f})\n",
    "    print(\"Résultat de l'API:\", response.json())\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors de l'appel à l'API :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd1de8-650f-40da-9687-ef222876f597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
